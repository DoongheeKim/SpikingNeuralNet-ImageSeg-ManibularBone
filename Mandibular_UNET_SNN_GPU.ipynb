{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print('tf.__version__=', tf.__version__)\n",
    "\n",
    "#Select GPU 0 or 1\n",
    "GPU_INDEX = 0 #1\n",
    "GPU_MEM = 0.95\n",
    "\n",
    "#GPU Configuration\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "gpu = '/gpu:'+ str(GPU_INDEX)\n",
    "\n",
    "#Set Memory limit (DO NOT OVER 5G!!!)\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[GPU_INDEX], \n",
    "                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=GPU_MEM*10*1024)])\n",
    "\n",
    "#install keras_spiking\n",
    "!pip install keras_spiking\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras_spiking\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imsave, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from measure import f_f1_score\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "#drive.flush_and_unmount()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pX631zhEouf4"
   },
   "source": [
    "## Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the size of raw images is 3100 x 1300 pixels\n",
    "IMG_WD= 128 #64  256\n",
    "IMG_HT= 64 #32 124\n",
    "\n",
    "IMG_CHANNELS = 1\n",
    "MASK_CHANNELS = 1\n",
    "n_steps = 120 #60\n",
    "\n",
    "#for data in the google drive\n",
    "DENT_FILE_PATH = '/content/drive/MyDrive/Colab Notebooks/DentalPanoramicXrays'\n",
    "\n",
    "IMAGE_FOLDER = \"Images\"\n",
    "MASK_FOLDER = \"Segmentation1\"\n",
    "\n",
    "image_path = DENT_FILE_PATH + \"/\" + IMAGE_FOLDER\n",
    "mask_path = DENT_FILE_PATH + \"/\" + MASK_FOLDER\n",
    "#print(\"image_path=\", image_path)\n",
    "#print(\"mask_path=\", mask_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pX631zhEouf4"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZkvOr7RV7xq"
   },
   "outputs": [],
   "source": [
    "def read_data(n_read_imgs, image_path, mask_path) :\n",
    "  image_train = np.zeros((n_read_imgs, IMG_HT, IMG_WD, IMG_CHANNELS), dtype=np.uint8)\n",
    "  mask_train = np.zeros((n_read_imgs, IMG_HT, IMG_WD, MASK_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "  sys.stdout.flush()\n",
    "  n_read = 0\n",
    "  for (root, dirs, files) in os.walk(image_path):\n",
    "    for id, file_name in enumerate(files):\n",
    "       img = imread(image_path + '/' + file_name)[:,:]\n",
    "\n",
    "       img = resize(img, (IMG_HT, IMG_WD), mode='constant', preserve_range=True)\n",
    "       img = img[..., np.newaxis]\n",
    "\n",
    "       image_train[id]= img\n",
    "       n_read = n_read + 1\n",
    "       if(n_read >= n_read_imgs) :\n",
    "          break\n",
    "       \n",
    "  print(\"Reading and resizing image files is done!\")\n",
    "  print()\n",
    "\n",
    "  sys.stdout.flush()  \n",
    "  n_read = 0\n",
    "  for (root, dirs, files) in os.walk(mask_path):\n",
    "    for id, file_name in enumerate(files):\n",
    "       mask = imread(mask_path + '/' + file_name)[:,:]\n",
    "       mask = resize(mask, (IMG_HT, IMG_WD), mode='constant', preserve_range=True)\n",
    "       mask = mask[..., np.newaxis]\n",
    "\n",
    "       mask_train[id]= mask\n",
    "       n_read = n_read + 1\n",
    "       if(n_read >= n_read_imgs) :\n",
    "          break\n",
    "\n",
    "  print(\"Reading and resizing mask files is done!\")\n",
    "  print()\n",
    "\n",
    "  #binarize mask_train\n",
    "  mask_threshold = 0\n",
    "  mask_train[mask_train > mask_threshold]  = 1\n",
    "  mask_train[mask_train <= mask_threshold]  = 0\n",
    "\n",
    "  #print(\"image_train.shape=\", image_train.shape)\n",
    "  #print(\"mask_train.shape=\", mask_train.shape)\n",
    "  #print()\n",
    "\n",
    "  n_train_imgs = int(n_read_imgs/2)\n",
    "  image_train_sequ = image_train[:n_train_imgs]\n",
    "  mask_train_sequ = mask_train[:n_train_imgs]\n",
    "  image_train_sequ = np.tile(\n",
    "    image_train_sequ[:, None], \n",
    "    (1, n_steps, 1, 1, 1))\n",
    "\n",
    "  image_test_sequ = image_train[n_train_imgs:]\n",
    "  mask_test_sequ = mask_train[n_train_imgs:]\n",
    "  image_test_sequ = np.tile(image_test_sequ[:, None], (1, n_steps, 1, 1, 1))\n",
    "\n",
    "\n",
    "  image_train = []\n",
    "  mask_train = []\n",
    "  return image_train_sequ, mask_train_sequ, image_test_sequ, mask_test_sequ\n",
    "\n",
    "def display(d_list, title):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "  #title = [\"Input Image\", \"True Mask\", \"Predicted Mask\"]\n",
    "\n",
    "  for i in range(len(d_list)):\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, len(d_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(d_list[i])) \n",
    "  plt.show()\n",
    "\n",
    "\n",
    "#n_read_imgs = 4\n",
    "n_read_imgs = len( next(os.walk(image_path))[2] )\n",
    "image_train_seq, mask_train_seq, image_test_seq, mask_test_seq = \\\n",
    "  read_data(n_read_imgs, image_path, mask_path) \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zJZHJdc037v"
   },
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print an image and its mask randomly chosen.\n",
    "random_index = np.random.choice(image_train_seq.shape[0])\n",
    "print(\"random_idx=\", random_index)\n",
    "sample_image, sample_mask = image_train_seq[random_index][0], mask_train_seq[random_index]\n",
    "display([sample_image, sample_mask], [\"sample_image\",\"sample_mask\"])\n",
    "\n",
    "#normalize image_train_seq to range between 0 and 1 ?\")\n",
    "if(image_train_seq.max() > 1) :\n",
    "  image_train_seq = image_train_seq/255\n",
    "  image_test_seq = image_test_seq/255\n",
    "\n",
    "#print(\"image_train_seq max=\", image_train_seq.max())\n",
    "#print(\"image_train_seq min=\", image_train_seq.min())\n",
    "\n",
    "'''\n",
    "### print 0-th components of all pixels of the middle row of sample_image \n",
    "print(\"print 0-th components of all pixels of the middle row of sample_image\")\n",
    "for x in range(IMG_WD):\n",
    "  print(sample_image[int(IMG_HT/2)][x][0], end = \" \")\n",
    "  if(x % 30 == 0) :\n",
    "     print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "#input(\"go?\")\n",
    "\n",
    "### print 0-th components of all pixels of the middle row of sample_mask \n",
    "print(\"print 0-th components of all pixels of the middle row of sample_mask\")\n",
    "for x in range(IMG_WD):\n",
    "  print(sample_mask[int(IMG_HT /2)][x][0], end = \" \")\n",
    "  if(x % 32 == 0) :\n",
    "     print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "#input(\"go?\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjBm4atL-i4i"
   },
   "source": [
    "## SNN-based U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2wwTBqaSJEJ4"
   },
   "outputs": [],
   "source": [
    "  def double_conv(z, n_filters, dt, sp_aware):\n",
    "    #Conv2D then ReLU activation\n",
    "    z = tf.keras.layers.TimeDistributed(layers.Conv2D(n_filters, 3, padding = \"same\", kernel_initializer = \"he_normal\"))(z)\n",
    "    z = keras_spiking.SpikingActivation(\"relu\", dt=dt, spiking_aware_training=sp_aware)(z)\n",
    "    \n",
    "    #Conv2D then ReLU activation\n",
    "    z = tf.keras.layers.TimeDistributed(layers.Conv2D(n_filters, 3, padding = \"same\",  kernel_initializer = \"he_normal\"))(z)\n",
    "    z = keras_spiking.SpikingActivation(\"relu\", dt=dt, spiking_aware_training=sp_aware)(z)\n",
    "\n",
    "    return z\n",
    "\n",
    "def downsample(z, n_filters, dt, sp_aware):\n",
    "    z1 = double_conv(z, n_filters, dt, sp_aware)\n",
    "    z2=tf.keras.layers.TimeDistributed(layers.MaxPool2D(2))(z1)\n",
    "    z2 = tf.keras.layers.TimeDistributed(layers.Dropout(0.3))(z2)\n",
    "    return z1, z2\n",
    "\n",
    "def upsample(z, conv_features, n_filters, dt, sp_aware):\n",
    "    #upsample\n",
    "    z = tf.keras.layers.TimeDistributed(layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\"))(z)\n",
    "    z = keras_spiking.SpikingActivation(\"relu\", dt=dt, spiking_aware_training=sp_aware)(z)\n",
    " \n",
    "    #concatenate \n",
    "    z = layers.concatenate([z, conv_features])\n",
    "\n",
    "    #dropout\n",
    "    z = tf.keras.layers.TimeDistributed(layers.Dropout(0.3))(z)\n",
    "\n",
    "    #Conv2D twice with ReLU activation\n",
    "    z = double_conv(z, n_filters, dt, sp_aware)\n",
    "\n",
    "    return z\n",
    "\n",
    "def build_unet_model(n_steps, dt, sp_aware):\n",
    "    # inputs\n",
    "    inputs = layers.Input(shape=(n_steps, IMG_HT, IMG_WD, IMG_CHANNELS))\n",
    "\n",
    "    #encoder:  downsample\n",
    "    #1 - downsample\n",
    "    f1, g1 = downsample(inputs, 64, dt, sp_aware)\n",
    "    #2 - downsample\n",
    "    f2, g2 = downsample(g1, 128, dt, sp_aware)\n",
    "    #3 - downsample\n",
    "    f3, g3 = downsample(g2, 256, dt, sp_aware)\n",
    "    #4 - downsample\n",
    "    f4, g4 = downsample(g3, 512, dt, sp_aware)\n",
    "\n",
    "    #5 - bottleneck\n",
    "    d_c = double_conv(g4, 1024, dt, sp_aware)\n",
    "\n",
    "    #decoder:  upsample\n",
    "    #6 - upsample\n",
    "    up6 = upsample(d_c, f4, 512, dt, sp_aware)\n",
    "    #7 - upsample\n",
    "    up7 = upsample(up6, f3, 256, dt, sp_aware)\n",
    "    #8 - upsample\n",
    "    up8 = upsample(up7, f2, 128, dt, sp_aware)\n",
    "    #9 - upsample\n",
    "    up9 = upsample(up8, f1, 64, dt, sp_aware)\n",
    "\n",
    "    #outputs\n",
    "    print(\"up9 shaoe before mean=\", up9.shape)\n",
    "    up9 = tf.reduce_mean(up9, 1)\n",
    "    print(\"u9 shaoe after mean=\", up9.shape)\n",
    "\n",
    "    outputs = layers.Conv2D(2, 1, padding=\"same\", activation = \"softmax\")(up9)\n",
    "\n",
    "    #unet model using Keras Functional API\n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "\n",
    "    return unet_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjBm4atL-i4i"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6wiP4It9QKm"
   },
   "outputs": [],
   "source": [
    "dt = 0.2\n",
    "N_EPOCHS = 50  #3\n",
    "BATCH_SIZE = 1#\n",
    "\n",
    "#for gpu on google colab\n",
    "with tf.device(gpu): \n",
    "\n",
    "  spiking_aware_train=True #$False #True\n",
    "  keras_spiking.default.dt = dt  # default 0.01\n",
    "\n",
    "  unet_model = build_unet_model(n_steps, dt, spiking_aware_train)\n",
    "  unet_model.summary()\n",
    "\n",
    "#for gpu on google colab\n",
    "with tf.device(gpu):\n",
    "\n",
    "  unet_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                   loss=\"sparse_categorical_crossentropy\",\n",
    "                   metrics=\"accuracy\"\n",
    "                   )\n",
    "  \n",
    "  earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "  print('earlystopper=', earlystopper )\n",
    "  checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\n",
    "  print('checkpointer=', checkpointer )\n",
    "\n",
    "  #hitory returns validation callbacks\n",
    "  history = unet_model.fit(image_train_seq, mask_train_seq,\n",
    "                     epochs=N_EPOCHS,\n",
    "                     validation_split=0.5, #TEMP 0.2\n",
    "                     batch_size = BATCH_SIZE, \n",
    "                     #steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                     #validation_steps=VALIDATION_STEPS,\n",
    "                     #validation_data=validation_batches\n",
    "                               )\n",
    "  \n",
    "#save the trained model in a h5 file, and can use it later\n",
    "#unet_model.save(\"unet_pet_KerasSpiking_model.h5\")\n",
    "#unet_model = tf.keras.models.load_model('unet_pet_KerasSpiking_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjBm4atL-i4i"
   },
   "source": [
    "## Test, Result Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-st0yc2KejK"
   },
   "outputs": [],
   "source": [
    "def gen_mask(pred_mask, idx):\n",
    "  pred_mask = tf.argmax(pred_mask, axis=-1) #axis=-1 means last axis\n",
    "  pred_mask = pred_mask[..., tf.newaxis]  # ... means \"as many ; as\"\n",
    " \n",
    "  return pred_mask[idx]\n",
    "\n",
    "def show_pred(model, sample_image, sample_mask):\n",
    "    pred = model.predict(sample_image[tf.newaxis,\n",
    "          ...])\n",
    "    pred_mask = gen_mask(pred, 0)\n",
    "    display([sample_image, sample_mask,pred_mask], \n",
    "\t[\"image\", \"mask\", \"pred_mask\"])\n",
    "  \n",
    "n_test_imgs = len(image_test_seq)\n",
    "preds = unet_model.predict(image_test_seq)\n",
    "\n",
    "#showing predictions and accuracies\n",
    "acc_sum = 0\n",
    "acc_f1_s = 0\n",
    "n_test = 0\n",
    "for test_idx in range(n_test_imgs) :\n",
    "  if(input(\"continue for showing predictionc ? (y or n)\") != \"y\"):\n",
    "    n_test = test_idx\n",
    "    break\n",
    "\n",
    "  pred_mask = gen_mask(preds, test_idx)\n",
    "  pred_mask = np.asarray(pred_mask)\n",
    "\n",
    "  etest_image = image_test_seq[test_idx][0]\n",
    "  etest_mask = mask_test_seq[test_idx]\n",
    "\n",
    "  display([etest_image, etest_mask], [\"etest_image\", \"etest_mask\"])\n",
    "  print()\n",
    "  print(\"test_idx=\", test_idx)\n",
    "  etest_image[pred_mask == 0] = 0\n",
    "  seg_img = etest_image\n",
    "  display([pred_mask, seg_img], [\"pred_mask\", \"segmented_test_image\"])\n",
    "\n",
    "  #accuracy calculaion\n",
    "  m = tf.keras.metrics.Accuracy()\n",
    "  m.update_state(pred_mask, etest_mask)\n",
    "  accuracy = m.result().numpy()\n",
    "  print(\"accuracy=\", accuracy, \"at idx=\", test_idx)\n",
    "  acc_sum = acc_sum +  accuracy\n",
    "\n",
    "  f1_s = f_f1_score(etest_mask, pred_mask)\n",
    "  print(\"f_f1_score=\", f1_s, \"at idx=\", test_idx)\n",
    "  acc_f1_s = acc_f1_s + f1_s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjBm4atL-i4i"
   },
   "source": [
    "### F1-Score, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(n_test == n_test_imgs) :\n",
    "  acc_mean = acc_sum / n_test_imgs \n",
    "  f1_s_mean = acc_f1_s / n_test_imgs \n",
    "else :\n",
    "  acc_mean = acc_sum / n_test \n",
    "  f1_s_mean = acc_f1_s / n_test\n",
    "\n",
    "print(\"accuracy mean = \", acc_mean)\n",
    "print(\"f1_score mean = \", f1_s_mean)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "53lnZ7YJe5Sw",
    "pX631zhEouf4",
    "2AR5ZItbpc9R",
    "QM9zPoS4phZl",
    "8zJZHJdc037v"
   ],
   "provenance": [
    {
     "file_id": "https://github.com/margaretmz/image-segmentation/blob/main/unet_pet_segmentation.ipynb",
     "timestamp": 1675340535980
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
